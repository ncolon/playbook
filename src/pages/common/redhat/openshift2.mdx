---
title: OpenShift Value Proposition
description: Technical content on Red Hat OpenShift
---

import { Link } from "gatsby";
import FileLink from "../../../components/FileLink";

In order to understand the value proposition of Red Hat OpenShift Container
Platform, we must first step back and understand the value that containerized
applications bring over traditional workloads running on physical or virtual
machines. Once those are understood, we need to look at how a distributed
platform like Kubernetes further abstracts the underlying compute,
storage and networking infrastructure, and the orchestration benefits it
provides over stand-alone containertized application deployments. Finally,
we must look at the common issues associated with Kubernetes, and how OpenShift
addresses those concerns.

## Containers value proposition

Containers are standard unit of software that packages up an application, all its
dependencies and configuration into a single image, so the application runs quickly
and reliably from one computing environment to another.

Containers work by isolating the differences between applications inside the
container so that everything outside the container can be standardized. This
makes it easy to move the contained application between environments (dev,
test, production, etc..) while retaining full functionality.

Containers are an important part of IT security. By building security into the
container pipeline and defending the infrastructure, the containers are
ensured to be reliable, scalable, and trusted.

Creating containerized applications offers many benefits.

### Containerized Application Benefits

#### Portability

Because a container bundles all dependencies, you can take your application just
about anywhere without rebuilding it to account for a new environment. The
abstraction provided by containerization ensures that your container works
the same way regardless of where you deploy it. That means you can take your app
to the cloud, run it on in a VM, or go directly to bare metal. As long as the host
operating system supports your containerization tools, you are ready to deploy with
minimal hassle.

#### Efficiency

When deploying an application on a virtual machine or physical host, you have to
allocate compute resources ahead of time. Often, resources will be overallocated
so that an application can meet its performance requirements in extreme edge cases.

With containers, you can deliver higher utilization of compute resources by
deploying two or more containers on the same host. Since containers package
their own dependencies, you won't run the risk of incompatible libraries between
two applications.

Since all the software dependencies for an application are resolved within the
container itself, you can use a standardized operating system on each host in
your data center. You do not need to configure a specific operating system for
each application host. When your data center needs more capacity, you can deploy
another generic host system.

#### Agility

Containers make it easier for developers to integrate with their existing [DevOps](https://www.ibm.com/topics/devops)
environment. If you employ rolling upgrades between major releases of your application,
you can continuously improve your applications without downtime and still maintain
compatibility with the current release. You can also deploy and test a new version of
an application alongside the existing version. If the container passes your tests,
simply deploy more new containers and remove the old ones.

#### Faster Delivery

Higher speed in the delivery of enhancements. Containerizing monolithic applications
using microservices helps development teams create functionality with its own life
cycle and scaling policies. Upgrading an existing application is as easy as deploying
its new containerized image, with any updated dependency already incldued in its image.

Microservices take apart much larger applications by segmenting pieces into containers.
This division makes it much easier for developers to implement changes and deploy new
code. You can change isolated areas of the application without affecting the whole.

Should you need to roll back any changes, you can deploy the original image, along with
its original dependencies.

#### Improved security

Improved security by isolating applications from the host system and from each
other. Any security breach in one workload will not impact any other workload
or the host they're running on.

#### Faster app startup

Compared to other methods of virtualization, containers are quite lightweight. One of
the many benefits of being lightweight is rapid startup times. Because a container
doesn’t rely on a hypervisor or virtualized operating system to access computing
resources, startup times are virtually instantaneous.

The only limiting factor is the application itself. With no substantial overhead to
wait for, the only startup delay is from your code and runtime environment. Rapid
startup is a great reason for frequent updates and improvements.

#### Flexibility

Flexibility to work on virtualized infrastructures or on bare metal servers.
Containerization allows developers the versatility to operate their code in either a
virtualized or bare-metal environment. Whatever the demands of deployment,
containerization can rise to meet them. Should there be a sudden need to retool your
environment from metal to virtual or vice versa, your containerized applications are
already prepared to make the switch.

## Kubernetes value proposition

Kubernetes is a portable, extensible, open-source container orchestration system
for automating deployment, scaling, and management of containerized applications.
It further enhances your containerization strategy. These are some of the main
benefits Kubernetes provides on top of containers.

#### Automated Rollouts and Rollbacks

Kubernetes progressively rolls out changes to your application or its configuration,
while monitoring application health to ensure it doesn't kill all your instances at
the same time. If something goes wrong, Kubernetes will rollback the change for you.
Take advantage of a growing ecosystem of deployment solutions.

<Link
  to="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/"
  target='_blank' rel='noreferrer noopener'
>
  Learn more
</Link>

#### Service discovery and load balancing

No need to modify your application to use an unfamiliar service discovery mechanism.
Kubernetes gives Pods their own IP addresses and a single DNS name for a set of Pods,
and can load-balance across them.

<Link
  to="https://kubernetes.io/docs/concepts/services-networking/service/"
  target='_blank' rel='noreferrer noopener'
>
  Learn more
</Link>

#### Storage orchestration

Automatically mount the storage system of your choice, whether from local storage,
a public cloud provider such as AWS or GCP, or a network storage system such as
NFS, iSCSI, Ceph, Cinder.

<Link
  to="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/"
  target='_blank' rel='noreferrer noopener'
>
  Learn more
</Link>

#### Secret and configuration management

Deploy and update secrets and application configuration without rebuilding your
image and without exposing secrets in your stack configuration.

<Link
  to="https://kubernetes.io/docs/concepts/configuration/secret/"
  target='_blank' rel='noreferrer noopener'
>
  Learn more
</Link>

#### Automatic bin packing

Automatically places containers based on their resource requirements and other
constraints, while not sacrificing availability. Mix critical and best-effort
workloads in order to drive up utilization and save even more resources.

<Link
  to="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"
  target='_blank' rel='noreferrer noopener'
>
  Learn more
</Link>

#### Batch execution

In addition to services, Kubernetes can manage your batch and CI workloads,
replacing containers that fail, if desired.

<Link
  to="https://kubernetes.io/docs/concepts/workloads/controllers/job/"
  target='_blank' rel='noreferrer noopener'
>
  Learn more
</Link>

#### Horizontal scaling

Scale your application up and down with a simple command, with a UI, or automatically
based on CPU usage.

<Link
  to="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
  target='_blank' rel='noreferrer noopener'
>
  Learn more
</Link>

#### Self-healing

Restarts containers that fail, replaces and reschedules containers when nodes die,
kills containers that don't respond to your user-defined health check, and doesn't
advertise them to clients until they are ready to serve.

<Link
  to="https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/#how-a-replicationcontroller-works"
  target='_blank' rel='noreferrer noopener'
>
  Learn more
</Link>

#### Designed for extensibility

Add features to your Kubernetes cluster without changing upstream source code.

<Link
  to="https://kubernetes.io/docs/concepts/extend-kubernetes/"
  target='_blank' rel='noreferrer noopener'
>
  Learn more
</Link>

## OpenShift value proposition

Red Hat OpenShift is an enterprise-ready Kubernetes container platform built for an <Link to="https://www.redhat.com/en/products/open-hybrid-cloud" target="_target">open hybrid cloud</Link> strategy. It provides a consistent application platform to manage hybrid cloud, multicloud, and edge deployments. This strategy gives developers a common application environment to develop, orchestrate, and run their applications, while giving sysadmins and operations teams a common operating environment to manage their infrastructure. With this consistency across environments you can deliver automated IT infrastructure.

Linux, Containers and Kubernetes are the architecture of choice. Containers drive portability and Kubernetes standardizes container management However, cloud provider specific Kubernetes lacks compatibility and integration guarantees (storage, networking, projects supported, etc..). OpenShift extends Kubernetes with built-in authentication and authorization, secrets management, auditing, logging, and container registry for granular, centralized control.

OpenShift is the leading enterprise Kubernetes platform: RHEL supports any cloud, any virtualization and any hardware and OpenShift provides everything out-of-the-box.

#### Automation

- Installation, upgrades, and lifecycle management throughout the container stack – operating system, Kubernetes and cluster services, and applications – on any public/private cloud, VMWare, bare metal
- Auto scaling and health management
- <Link
    to="https://www.redhat.com/en/technologies/cloud-computing/openshift/what-are-openshift-operators"
    target='_blank' rel='noreferrer noopener'
  >
    Operators
  </Link> (a method of packaging, deploying and managing a Kubernetes-native application)
  provide automation at every level of the stack, from managing the parts that make
  up the platform to applications that are provided as a managed service.

#### Collaboration

- IT operations and developers to effectively deploy containerized applications
- Support for <Link to="https://www.redhat.com/en/topics/devops/what-is-ci-cd" target='_blank' rel='noreferrer noopener'>CI/CD</Link> workflows and pipelines, and integration with CI/CD pipeline and toolchain
- OpenShift is an application platform with a trusted software supply chain
- Management of container images with ImageStreams (e.g. upload a container image once and manage it)
- Provides capability to plug-in any open source or customized tools that customer teams prefer to use

#### Standards based

- Cloud Native Computing Foundation (CNCF) and the Open Container Initiative (OCI)
- Portability of workloads between onsite, public and private cloud and across an array of systems which run RHEL/RH CoreOS
- Portability of container images built on OCI standard between development, test, and production environments

#### Web scale

- Build, deploy and manage applications at scale on containers without worrying about containers and technical details which in turn allows people to concentrate on business innovation and results
- Scalability, easily scale applications to thousands of instances across hundreds of nodes in a matter of seconds.

#### Open source

- RedHat is the leading Kubernetes contributor since day one
- Use continuous feedback loop to expedite fixes and innovation from customer to community and back to customer

#### Enterprise grade

- Enterprise-grade Linux operating system (RH CoreOS or RHEL)
- Focused on security at every level of the container stack and throughout the application lifecycle, container orchestration and cluster management, and enterprise container host
- Stricter security policies and default configurations out of the box than default Kubernetes
- 24x7 external support organization available for your production application environment via a subscription model
- Operators via OperatorHub including OpenShift certified operators starting in OpenShift 4.0
